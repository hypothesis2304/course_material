{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-559e06fab022e928",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "In the previous assignment we have implemented a neural network in raw numpy. The goal of this assignment is to make you familiar with PyTorch and build a model in PyTorch for FashionMnist data for Image classification. In this assignment, we build a Convolutional Neural Networks which are better for Image Classification. PyTorch is a deep learning framework that allows us to work on GPUs and PyTorch is very similar to python. \n",
    "\n",
    "In summary, we will implement a image classifier based on Convolutional Neural Networks for FashionMNIST dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-675473914c4b9f68",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "## Imports\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import dataset\n",
    "\n",
    "## Checks for the availability of GPU \n",
    "if torch.cuda.is_available():\n",
    "    print(\"working on gpu!\")\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print(\"No gpu! only cpu ;)\")\n",
    "    device = 'cpu'\n",
    "    \n",
    "## The following random seeds are just for deterministic behaviour of the code and evaluation\n",
    "\n",
    "##############################################################################\n",
    "################### DO NOT MODIFY THE CODE BELOW #############################    \n",
    "##############################################################################\n",
    "\n",
    "if device == 'cpu':    \n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "elif device == 'cuda':\n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = '42'\n",
    "\n",
    "############################################################################### \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9c87add622617c1e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Arranging the data\n",
    "\n",
    "In the following cell we will be loading the data. FashionMNIST data is made available in the official PyTorch repositories. The following cell checks for the availability of data and downloads if the data is not available.   \n",
    "\n",
    "The following parts are already written for you in the next cell for handling the data.\n",
    "- import the pytorch packages for data handling.\n",
    "- The only transformation we apply are moving the data numpy arrays to Tensors (transoforms.ToTensor())\n",
    "- define the parameters for data handling. A different batch_size for test data is used to make sure that number     of samples in the test data are perfectly divisible.\n",
    "- create dataloaders for train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e518bb36bae17b30",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "\n",
    "if not os.path.isdir('./data'):\n",
    "    os.mkdir('./data')\n",
    "root = './data/'\n",
    "\n",
    "training_data = torchvision.datasets.FashionMNIST(root, train=True, transform=transforms.ToTensor(),download=True)\n",
    "testing_data = torchvision.datasets.FashionMNIST(root, train=False, transform=transforms.ToTensor(),download=True)\n",
    "\n",
    "train_bs = 32\n",
    "test_bs = 8\n",
    "\n",
    "\n",
    "train_loader=torch.utils.data.DataLoader(dataset=training_data, batch_size=train_bs, shuffle=True, drop_last=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=testing_data, batch_size=test_bs, shuffle=True, drop_last=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peek into data\n",
    "\n",
    "In any problem, it is always important to study the data first. It will help us to have a better idea on the data and provide a good intuition about the requirements of the model to be built. In the following cell we peek into a random batch of images and visualize them along with their labels.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1168a8b4140174bf",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-aae68e01a33d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m## get a batch of data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "## get a batch of data\n",
    "images, labels = iter(train_loader).next()\n",
    "\n",
    "\n",
    "image_dict = {0:'T-shirt/Top', 1:'Trouser', 2:'Pullover', 3:'Dress',\n",
    "              4:'Coat', 5:'Sandal', 6:'Shirt', 7:'Sneaker',\n",
    "              8:'Bag', 9:'Ankle Boot'}\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "for i in np.arange(1, 13):\n",
    "    ax = fig.add_subplot(3,4,i, frameon=False)\n",
    "    img = images[i][0]\n",
    "    ax.set_title(image_dict[labels[i].item()])\n",
    "    plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture\n",
    "\n",
    "We implement the following layers in our model.\n",
    "- a convolution layer for extracting spatial relationships.\n",
    "- batchnorm layer for normalizing the weights in the hidden layers\n",
    "- ReLU activation function for the non-linearity between layers\n",
    "- dropout for regularization\n",
    "- and finally fully connected layers in the end\n",
    "\n",
    "#### Model:\n",
    "\n",
    "we build the following convolutional neural network architecture on the dataset. \n",
    "\n",
    "- convolution layer output_channels-16 kernel_size=5 stride=1 padding-2\n",
    "- batchnormalization layer\n",
    "- ReLU activation layer\n",
    "- maxpool layer kernel_size=2 stride=2\n",
    "- convolution layer output_channels-32 kernel_size=5 stride=1 padding-2\n",
    "- batchnormalization layer\n",
    "- ReLU activation layer\n",
    "- maxpool layer kernel_size=2 stride=2\n",
    "- fully connected layer 256\n",
    "- fully connected layer number_of_classes\n",
    "\n",
    "### Build the model\n",
    "\n",
    "- We first define a class called Model.\n",
    "- In init, we will define all the layers that will be used to build the model\n",
    "- Forward builds the sequential model taking in Input and returns the Output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-377cf97e5126cc8a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    ## init function is the model initializer.\n",
    "    ## we define all the layers used in our model. \n",
    "    def __init__(self, num_classes=8):\n",
    "        super(Model, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=2)\n",
    "#         self.bn1 = nn.BatchNorm2d(16)\n",
    "        ''' \n",
    "        REST OF THE MODEL HERE\n",
    "        \n",
    "        ## define a relu layer and as it don't have any parameters it can be reused\n",
    "        \n",
    "        ## define a maxpool layer as it has zero parameters it can be reused\n",
    "        \n",
    "        ## define a convolution layer with provided parameters \n",
    "        \n",
    "        ## define a batchnorm layer, the num_features is the same as number of output channels from previous layer\n",
    "        \n",
    "        ## As relu and maxpool are parameterless layers, they can be reused.\n",
    "        ## define a fully connected layer with input_size = flattened output of previous layer, output=defined size\n",
    "        \n",
    "        ## define a fully connected layer with input_size=output_size of previous layer and output_size=num_classes\n",
    "        \n",
    "        '''\n",
    "        ### BEGIN SOLUTION \n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.fc1 = nn.Linear(1568,256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        ### END SOLUTION \n",
    "        \n",
    "    def forward(self, x):\n",
    "        ### BEGIN SOLUTION\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        ### END SOLUTION\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        \n",
    "        '''\n",
    "        REST OF THE FORWARD CODE HERE.\n",
    "        \n",
    "        \n",
    "        Note that before the fully connected(fc) layer, the output is a feature map with size (N,C,H,W)\n",
    "        but a fully connected layers expects a input of size (N, some-number). so before passing the output of maxpool\n",
    "        layer to fc layer we must first flatten the output of previous layer to a size (N,C*H*W) and then pass\n",
    "        it to the fully connected layer.  \n",
    "        \n",
    "        To flatten the output of the layer before fc layer pass it through the flatten function first and then \n",
    "        input it to the fully connected layer.\n",
    "         \n",
    "        '''\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def flatten(self, x):\n",
    "        N, C, H, W = x.size()\n",
    "        ## CODE HERE\n",
    "        ## reshape x to (N, C*H*W) \n",
    "        \n",
    "        ### BEGIN SOLUTION\n",
    "        x = x.view(N, C*H*W)\n",
    "        ### END SOLUTION\n",
    "        x = None\n",
    "        \n",
    "        return x\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-cd1cb5622fe024a9",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 10])\n"
     ]
    }
   ],
   "source": [
    "## Run the cell to check the implementation of your model\n",
    "model = Model(num_classes=10)\n",
    "test_input = torch.randn(16,1,28,28)\n",
    "out = model(test_input)\n",
    "\n",
    "### BEGIN HIDDEN TESTS\n",
    "assert(out.size()[0], [16,10])\n",
    "assert(torch.sum(out).item(), 6.7498)\n",
    "### END HIDDEN TESTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "epochs = 5\n",
    "number_of_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a loss criterion, In this assignment we will use cross-entropy loss between the predictions and ground truth to estimate the loss. \n",
    "- CrossEntropyLoss - https://pytorch.org/docs/stable/nn.html#crossentropyloss\n",
    "\n",
    "We also define a optimization strategy to update the weights. In this assignment we use Stochastic Gradient descent with Nesterov momentun from the PyTorch package. \n",
    "\n",
    "- SGD - https://pytorch.org/docs/stable/optim.html#algorithms (scroll to optim.SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First we will define an instance of the model to train\n",
    "model = Model(num_classes=number_of_classes)\n",
    "\n",
    "# define the loss\n",
    "### BEGIN SOLUTION\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "### END SOLUTION\n",
    "criterion = None\n",
    "\n",
    "# optimizer for the model, here we use adam optimizer with a learning rate=0.001 and rest default parameters.  \n",
    "### BEGIN SOLUTION\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9, nesterov=True)\n",
    "### END SOLUTION\n",
    "\n",
    "optimizer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training loop is setup in the following way:\n",
    "\n",
    "For every batch in the defined number of epochs\n",
    "\n",
    "- Move the images and labels to the device\n",
    "- Extract output by passing input through the model \n",
    "- pass the output and ground truth to the loss criterion for batch loss\n",
    "- clear the gradients \n",
    "- backpropagate (compute gradients w.r.t the parameters)\n",
    "- update the parameters with a single optimization step\n",
    "- update the training loss for plots\n",
    "\n",
    "repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training loop \n",
    "\n",
    "## Number of epochs the model runs\n",
    "for epoch in range(epochs):\n",
    "    # Iterate through the batches in the data\n",
    "    training_loss = 0.0\n",
    "    for idx,(images,labels)  in enumerate(train_loader):\n",
    "        ### BEGIN SOLUTION\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        training_loss += loss.item()\n",
    "        ### END SOLUTION\n",
    "        '''\n",
    "        CODE HERE\n",
    "        '''\n",
    "        \n",
    "        ## Move the images to the device\n",
    "        \n",
    "        ## Move the labels to the device\n",
    "        \n",
    "        ## Get the output of the model by passing input to the model\n",
    "        \n",
    "        ## Find the loss of the input batch by passing output & ground truths to the criterion\n",
    "        \n",
    "        ## clear the gradients\n",
    "        \n",
    "        ## compute the gradients by backpropagating through the computational graph.\n",
    "        \n",
    "        ## update the parameters \n",
    "        \n",
    "        \n",
    "        if idx % 1000 == 0:\n",
    "            print('Cross Entropy Loss: {:0.4f} Epoch [{}/{}] Iter: {}'.format(loss.item(), epoch, epochs, idx))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Loop\n",
    "\n",
    "In the testing loop we don't update the weights. The trained model is tested for all the samples in test data to compute the accuracy and observe how well the model is generalizing to the unseen data. \n",
    "\n",
    "The testing loop is setup in the following way: \n",
    "\n",
    "For every batch in the testing data\n",
    "\n",
    "- Turn off the gradients\n",
    "- Move the images and labels to the device available\n",
    "- extract output from the model for the input\n",
    "- compute the prediction class by choosing the one with maximum probability in the predictions.\n",
    "- Compare the prediction classes with true classes.\n",
    "- calculate accuracy\n",
    "- update test_loss for plots\n",
    "\n",
    "repeat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing Loop\n",
    "\n",
    "with torch.no_grad:\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        ### BEGIN SOLUTION\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        test_loss += loss.item()\n",
    "        _, predict = torch.max(output, dim=1)\n",
    "        correct += torch.sum(torch.squeeze(predict).cpu() == labels).item()\n",
    "        \n",
    "        ### END SOLUTION\n",
    "        '''\n",
    "        YOUR CODE HERE\n",
    "        '''\n",
    "        ## Move the images to the device\n",
    "        \n",
    "        ## Move the labels to the device\n",
    "        \n",
    "        ## Get the output of the model by passing images as input to the model\n",
    "        \n",
    "        ## Find the loss of a batch by passing output & ground truths to the criterion\n",
    "        \n",
    "        ## \n",
    "        \n",
    "        \n",
    "        total_samples += label.size(0)\n",
    "    print(\"Total Accuracy on the Test set: {} %\".format(correct/total*100))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize the test samples with predicted output and true output\n",
    "images, labels = iter(test_loader).next()\n",
    "images = images.numpy()\n",
    "images = images.to(device)\n",
    "\n",
    "out = model(images)\n",
    "_, preds = torch.max(out, dim=1)\n",
    "\n",
    "if device == 'cuda':\n",
    "    preds = np.squeeze(preds.numpy())\n",
    "else:\n",
    "    preds = np.squeeze(preds.cpu().numpy())\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in np.arange(1, 13):\n",
    "    ax = fig.add_subplot(4, 3, i)\n",
    "    imshow(images[i])\n",
    "    ax.set_title(\"Pred: {} True: {}\".format(classes[preds[i]], classes[labels[i]]), \n",
    "                color=('green' if preds[i] == labels[i] else 'red'))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
