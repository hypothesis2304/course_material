{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now, we have implemented manually in raw numpy. The goal of this assignment is to make you familiar with PyTorch and work with Convolutional Neural Networks which are better in Image classification. PyTorch is a deep learning framework and working with it is very similar to python. The major advantages it provides are:\n",
    "\n",
    "- Work with GPUs\n",
    "- Has automatic differentiation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this, assignment we will implement a classifier based on Convolutional Neural Network on SVHN dataset. A CNN is a more suitable type of architecture to process image data. Following is the architecture we will build  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No gpu! only cpu ;)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import dataset\n",
    "if torch.cuda.is_available():\n",
    "    print(\"working on gpu!\")\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print(\"No gpu! only cpu ;)\")\n",
    "    device = 'cpu'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arranging the data\n",
    "\n",
    "In the following cell we will be loading the data that is already downloaded and made available for you in the servers. \n",
    "\n",
    "We implement the following parts in the next cell.\n",
    "- import the pytorch packages which help us in data handling initially. (done it for you!)\n",
    "- define the train and test transforms to be applied on the input\n",
    "- create dataloaders for train and test data\n",
    "- define the parameters for data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "train_transform = None\n",
    "test_transform = None\n",
    "\n",
    "train_loader = None\n",
    "test_loader = None\n",
    "\n",
    "train_bs = 32\n",
    "test_bs = 8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peek into data\n",
    "\n",
    "In general, it is always important study the data from every angle to build a good discriminative model. It will help us to notice things and give a good understanding of the requirements of our model. In the following cell we just peek into a random batch of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d1037d4f76cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m## get a batch of data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mimages\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "# importing a graphics  library for visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "## get a batch of data\n",
    "images, labels = iter(train_loader)\n",
    "images  = images.numpy()\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for i in np.arange(1, 13):\n",
    "    ax = fig.add_subplot(3,4,i, frameon=False)\n",
    "    img = images[i]\n",
    "    img = img /2 + 0.5\n",
    "    img = np.transpose(img, (1,2,0))\n",
    "    plt.imshow(img)\n",
    "    ax.set_title(labels[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture\n",
    "\n",
    "We use the following layers in our model.\n",
    "- a convolution layer for extracting spatial relationships.\n",
    "- batchnorm layer for normalizing the weights in the hidden layers\n",
    "- ReLU activation function for the non-linearity between layers\n",
    "- dropout for regularization\n",
    "- and finally fully connected layers in the end\n",
    "\n",
    "#### Model:\n",
    "\n",
    "we build the following convolutional neural network architecture on the dataset. \n",
    "\n",
    "- convolution layer output_channels-16 kernel_size=5 stride=1 padding-2\n",
    "- batchnormalization layer\n",
    "- ReLU activation layer\n",
    "- maxpool layer kernel_size=2 stride=2\n",
    "- convolution layer output_channels-32 kernel_size=5 stride=1 padding-2\n",
    "- batchnormalization layer\n",
    "- ReLU activation layer\n",
    "- maxpool layer kernel_size=2 stride=2\n",
    "- fully connected layer 256\n",
    "- fully connected layer number_of_classes\n",
    "\n",
    "### Build the model\n",
    "\n",
    "- We first define a class called Model.\n",
    "- In init, we will define all the layers that will be used to build the model\n",
    "- Forward builds the sequential model taking in Input and returns the Output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-604ed81c01c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;31m## init function is the model initializer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m## we define all the layers used in our model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class Model(nn.module):\n",
    "    ## init function is the model initializer.\n",
    "    ## we define all the layers used in our model. \n",
    "    def __init__(self, num_classes=8):\n",
    "        self.conv1 = nn.Conv2D(3, 16, kernel_size=5, stride=1, pad=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        ''' \n",
    "        REST OF THE MODEL HERE\n",
    "        '''\n",
    "        \n",
    "    def forward(x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        '''\n",
    "        CODE HERE\n",
    "        '''\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = None\n",
    "learning_rate = None\n",
    "epochs = None\n",
    "number_of_classes = 10\n",
    "classes = {0 :'T-shirt/top',\n",
    "                  1 :'Trouser',\n",
    "                  2 :'Pullover',\n",
    "                  3 :'Dress',\n",
    "                  4 :'Coat',\n",
    "                  5 :'Sandal',\n",
    "                  6 :'Shirt',\n",
    "                  7 :'Sneaker',\n",
    "                  8 :'Bag',\n",
    "                  9 :'Ankle boot'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define a instance of the class Model and name it as \"model\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## move the model to 'GPU' if available else 'cpu'\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a loss criterion, In this assignment we will use cross-entropy loss between the predictions and ground truth to estimate the loss. \n",
    "- CrossEntropyLoss - https://pytorch.org/docs/stable/nn.html#crossentropyloss\n",
    "\n",
    "We also define a optimization strategy to update the weights. In this assignment we use Stochastic Gradient descent with Nesterov momentun from the PyTorch package. \n",
    "\n",
    "- SGD - https://pytorch.org/docs/stable/optim.html#algorithms (scroll to optim.SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the loss\n",
    "loss = None\n",
    "\n",
    "# optimizer for the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training loop is setup in the following way:\n",
    "\n",
    "For every batch in the defined number of epochs\n",
    "\n",
    "- Move the images and labels to the device\n",
    "- Extract output by passing input through the model \n",
    "- pass the output and ground truth to the loss criterion for batch loss\n",
    "- clear the gradients \n",
    "- backpropagate (compute gradients w.r.t the parameters)\n",
    "- update the parameters with a single optimization step\n",
    "- update the training loss for plots\n",
    "\n",
    "repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training loop \n",
    "\n",
    "## Number of epochs the model runs\n",
    "for epoch in range(epochs):\n",
    "    # Iterate through the batches in the data\n",
    "    training_loss = 0.0\n",
    "    for idx,(images,labels)  in enumerate(train_loader):\n",
    "        '''\n",
    "        CODE HERE\n",
    "        '''\n",
    "        \n",
    "        if idx % 1000 == 0:\n",
    "            print('Cross Entropy Loss: {:0.4f} Epoch [{}/{}] Iter: {}'.format(loss.item(), epoch, epochs, idx))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Loop\n",
    "\n",
    "In the testing loop we don't update the weights. The trained model is tested for all the samples in test data to compute the accuracy and observe how well the model is generalizing to the unseen data. \n",
    "\n",
    "The testing loop is setup in the following way: \n",
    "\n",
    "For every batch in the testing data\n",
    "\n",
    "- Turn off the gradients\n",
    "- Move the images and labels to the device available\n",
    "- extract output from the model for the input\n",
    "- compute the prediction class by choosing the one with maximum probability in the predictions.\n",
    "- Compare the prediction classes with true classes.\n",
    "- calculate accuracy\n",
    "- update test_loss for plots\n",
    "\n",
    "repeat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing Loop\n",
    "\n",
    "with torch.no_grad:\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        '''\n",
    "        YOUR CODE HERE\n",
    "        '''\n",
    "        total_samples += label.size(0)\n",
    "    print(\"Total Accuracy on the Test set: {} %\".format(correct/total*100))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize the test samples with predicted output and true output\n",
    "images, labels = iter(test_loader).next()\n",
    "images = images.numpy()\n",
    "images = images.to(device)\n",
    "\n",
    "out = model(images)\n",
    "_, preds = torch.max(out, dim=1)\n",
    "\n",
    "if device == 'cuda':\n",
    "    preds = np.squeeze(preds.numpy())\n",
    "else:\n",
    "    preds = np.squeeze(preds.cpu().numpy())\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in np.arange(1, 13):\n",
    "    ax = fig.add_subplot(4, 3, i)\n",
    "    imshow(images[i])\n",
    "    ax.set_title(\"Pred: {} True: {}\".format(classes[preds[i]], classes[labels[i]]), \n",
    "                color=('green' if preds[i] == labels[i] else 'red'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
